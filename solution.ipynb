{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Load data numerical, categorical and target`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numericals shape: (95412, 315)\n",
      "Categoricals shape: (95412, 22)\n",
      "Targets shape: (95412, 2)\n"
     ]
    }
   ],
   "source": [
    "numericals = pd.read_csv('files_for_lab/numerical.csv')\n",
    "categoricals = pd.read_csv('files_for_lab/categorical.csv')\n",
    "targets = pd.read_csv('files_for_lab/target.csv')\n",
    "\n",
    "print(f\"Numericals shape: {numericals.shape}\")\n",
    "print(f\"Categoricals shape: {categoricals.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "important_columns = ['WEALTH1', 'WEALTH2', 'VETERANS', 'SOLIH']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Numericals - RFE`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = MinMaxScaler()\n",
    "numericals_scaled = min_max_scaler.fit_transform(numericals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are '290' columns to drop.\n"
     ]
    }
   ],
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "# Create an instance of the RFE class\n",
    "rfe = RFE(model, n_features_to_select=25, verbose=False)\n",
    "\n",
    "# Fit the RFE to the DataFrame\n",
    "rfe.fit(numericals_scaled, targets[['TARGET_B']])\n",
    "\n",
    "# Get the boolean mask of the selected columns\n",
    "mask = rfe.support_\n",
    "\n",
    "# Use the mask to obtain the names of the selected columns\n",
    "columns_to_drop = numericals.columns[~mask]\n",
    "\n",
    "print(f\"There are '{len(columns_to_drop)}' columns to drop.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 27)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_to_drop = [col for col in columns_to_drop if col not in important_columns]\n",
    "numericals_rfe = numericals.drop(columns_to_drop, axis=1)\n",
    "numericals_rfe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 24)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numericals_rfe_manual_drop = numericals_rfe.drop(['POP90C1', 'DW1', 'MC2'], axis=1)\n",
    "numericals_rfe_manual_drop.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Categoricals`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "object_columns_from_categoricals = [col for col in categoricals.columns if categoricals[col].dtype == object]\n",
    "for col in object_columns_from_categoricals:\n",
    "    categoricals[col] = pd.factorize(categoricals[col])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(95412, 21)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'RFA_2R' has only 1 unique value so we can drop it\n",
    "\n",
    "categoricals.drop('RFA_2R', axis=1, inplace=True)\n",
    "categoricals.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Try Oversampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90569, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_b = targets[['TARGET_B']]\n",
    "target_b['TARGET_B'].value_counts()\n",
    "\n",
    "target_b_0 = target_b[target_b['TARGET_B'] == 0]\n",
    "target_b_1 = target_b[target_b['TARGET_B'] == 1]\n",
    "\n",
    "target_b_1_undersampled = resample(target_b_1, replace=True, n_samples=len(target_b_0))\n",
    "target_b_1_undersampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    90569\n",
       "1    90569\n",
       "Name: TARGET_B, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_b_oversampled = pd.concat([target_b_0, target_b_1_undersampled], axis=0).sample(frac=1)\n",
    "target_b_oversampled['TARGET_B'].value_counts()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Check accuracy with sets of selected columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_full_dfs_tuples(targets, selected_numericals_df_tuples):\n",
    "    return [\n",
    "        (sub_df[0], pd.concat([targets, sub_df[1], categoricals], axis=1).dropna(axis=0))\n",
    "            for sub_df in selected_numericals_df_tuples\n",
    "    ]\n",
    "\n",
    "def score_selected_columns(targets, selected_numericals_df_list):\n",
    "    index = 1\n",
    "    df_tuples = get_full_dfs_tuples(targets, selected_numericals_df_list)\n",
    "    for tuple in df_tuples:\n",
    "\n",
    "        print(\"================================\")\n",
    "        print(f\"{tuple[0]}\")\n",
    "\n",
    "        y = tuple[1]['TARGET_B']\n",
    "        X = tuple[1].drop('TARGET_B', axis=1)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "        # Scaling data = X_train\n",
    "        X_train_transformer = MinMaxScaler().fit(X_train)\n",
    "        X_train_normalized = X_train_transformer.transform(X_train)\n",
    "        X_train_normalized = pd.DataFrame(X_train_normalized)\n",
    "\n",
    "        # Scaling data = X_test\n",
    "        X_test_transformer = MinMaxScaler().fit(X_test)\n",
    "        X_test_normalized = X_test_transformer.transform(X_test)\n",
    "        X_test_normalized = pd.DataFrame(X_test_normalized)\n",
    "\n",
    "        # Create an instance of the RandomForestClassifier\n",
    "        clf = RandomForestClassifier(max_depth=5,\n",
    "                             min_samples_split=20,\n",
    "                             min_samples_leaf=20)\n",
    "\n",
    "        # Fit the classifier to the training data\n",
    "        clf.fit(X_train_normalized, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = clf.predict(X_test_normalized)\n",
    "\n",
    "        # Calculate the accuracy of the model\n",
    "        display(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "        scores = cross_val_score(clf, X_train_normalized, y_train, cv=10)\n",
    "        # Print the mean and standard deviation of the scores\n",
    "        print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "        \n",
    "        print(\"================================\")\n",
    "\n",
    "        index += 1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `Without Oversampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "numericals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18166,     0],\n",
       "       [  917,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.00)\n",
      "================================\n",
      "================================\n",
      "numericals_rfe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18112,     0],\n",
       "       [  971,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.00)\n",
      "================================\n",
      "================================\n",
      "numericals_rfe_manual_drop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[18111,     0],\n",
       "       [  972,     0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95 (+/- 0.00)\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "selected_numericals_df_list = [\n",
    "    ('numericals', numericals), \n",
    "    ('numericals_rfe', numericals_rfe), \n",
    "    ('numericals_rfe_manual_drop', numericals_rfe_manual_drop)\n",
    "]\n",
    "\n",
    "score_selected_columns(targets[['TARGET_B']], selected_numericals_df_list)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `With Oversampling`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\n",
      "numericals\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[13176,  4968],\n",
       "       [ 9712,  8372]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.61 (+/- 0.01)\n",
      "================================\n",
      "================================\n",
      "numericals_rfe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[11926,  6122],\n",
       "       [ 8746,  9434]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59 (+/- 0.01)\n",
      "================================\n",
      "================================\n",
      "numericals_rfe_manual_drop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[16011,  2238],\n",
       "       [13667,  4312]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.59 (+/- 0.01)\n",
      "================================\n"
     ]
    }
   ],
   "source": [
    "score_selected_columns(target_b_oversampled, selected_numericals_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By Oversampling, we can predict with LESS accuracy people who will donate in opposite than without Oversampling.\n",
    "# But by Oversampling, we can predict with MORE accuracy people who will NOT donate. (with many errors though)\n",
    "# We can use these 2 different types of models (Oversampling / Not Oversampling) so we can predict with more accuracy people who will donate AND people who will NOT."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
